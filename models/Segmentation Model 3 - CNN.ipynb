{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "from optparse import OptionParser\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "import progressbar\n",
    "from torch.autograd import Function, Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from torchvision import transforms\n",
    "from glob import glob\n",
    "from skimage import io\n",
    "from sklearn.feature_extraction.image import extract_patches_2d,reconstruct_from_patches_2d\n",
    "import pickle\n",
    "from torch.utils.data import Dataset\n",
    "%matplotlib inline\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = progressbar.ProgressBar(widgets=[progressbar.Bar('*', '[', ']'), progressbar.Percentage(), ' '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_channels_in, n_channels_out):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(n_channels_in, 64, 3, 1, 1), #in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, stride =1,padding = 1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, stride =1,padding = 1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride =1,padding = 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride =1,padding = 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(256, n_channels_out, kernel_size=1,stride =1, padding = 0)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_masks, transforms=None): \n",
    "\n",
    "        self.image_masks = image_masks\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):  # return count of sample we have\n",
    "\n",
    "        return len(self.image_masks)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image = np.array(self.image_masks[index][0]) # Channel,H, W\n",
    "        mask = self.image_masks[index][1]\n",
    "        \n",
    "        sample = {'img': image, 'label': mask}\n",
    "        \n",
    "        if transforms:\n",
    "            sample = self.transforms(sample)\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flip(object):\n",
    "    \"\"\"\n",
    "    Flip the image left or right for data augmentation, but prefer original image.\n",
    "    \"\"\"\n",
    "    def __init__(self,ori_probability=0.60):\n",
    "        self.ori_probability = ori_probability\n",
    " \n",
    "    def __call__(self, sample):\n",
    "        if random.uniform(0,1) < self.ori_probability:\n",
    "            return sample\n",
    "        else:\n",
    "            img, label = sample['img'], sample['label']\n",
    "            img_flip = img[:,:,::-1]\n",
    "            label_flip = label[:,::-1]\n",
    "            \n",
    "            return {'img': img_flip, 'label': label_flip}\n",
    "        \n",
    "class ToTensor(object):\n",
    "    \"\"\"\n",
    "    Convert ndarrays in sample to Tensors.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['img'], sample['label']\n",
    "\n",
    "        return {'img': torch.from_numpy(image.copy()).type(torch.FloatTensor),\n",
    "                'label': torch.from_numpy(label.copy()).type(torch.FloatTensor)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_masks_save_path = 'Pickles/train_img_masks.pickle'\n",
    "if os.path.exists(train_img_masks_save_path):\n",
    "    with open(train_img_masks_save_path,'rb') as f:\n",
    "        train_img_masks = pickle.load(f)\n",
    "    f.close()\n",
    "else:\n",
    "    pickle_store(train_img_masks_save_path,train_img_masks)\n",
    "\n",
    "val_img_masks_save_path = 'Pickles/val_img_masks.pickle'\n",
    "if os.path.exists(val_img_masks_save_path):\n",
    "    with open(val_img_masks_save_path,'rb') as f:\n",
    "        val_img_masks = pickle.load(f)\n",
    "    f.close()\n",
    "else:\n",
    "    pickle_store(val_img_masks_save_path,val_img_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_img_masks, transforms=transforms.Compose([Flip(),ToTensor()]))\n",
    "val_dataset = CustomDataset(val_img_masks, transforms=transforms.Compose([Flip(),ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU(inplace=True)\n",
      "    (15): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "Number of parameters in network:  2255749\n"
     ]
    }
   ],
   "source": [
    "net = CNN(4,5).to(device,dtype=torch.float32)\n",
    "net.to(device) \n",
    "print(net)\n",
    "\n",
    "n_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print('Number of parameters in network: ', n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[                                                                        ]N/A% "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/100.\n",
      "0.0000 --- loss: 1.627502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*************                                                           ] 19% "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2000 --- loss: 1.417427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[****************************                                            ] 39% "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4000 --- loss: 1.319456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[******************************************                              ] 59% "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6000 --- loss: 1.223173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************************************************               ] 79% "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8000 --- loss: 1.285748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[                                                                        ]N/A% "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch finished ! Loss: 1.3638641834259033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[                                                                        ]N/A% "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Cross-Entropy Coeff: 1.3513823747634888\n",
      "Checkpoint 1 saved !\n",
      "Starting epoch 2/100.\n",
      "0.0000 --- loss: 1.325660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*************                                                           ] 19% "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2000 --- loss: 1.246531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[****************************                                            ] 39% "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4000 --- loss: 1.315305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[******************************************                              ] 59% "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6000 --- loss: 1.327999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************************************************               ] 79% "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8000 --- loss: 1.258097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[                                                                        ]N/A% "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch finished ! Loss: 1.2956554889678955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[                                                                        ]N/A% "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Cross-Entropy Coeff: 1.33510160446167\n",
      "Checkpoint 2 saved !\n",
      "Starting epoch 3/100.\n",
      "0.0000 --- loss: 1.195434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*************                                                           ] 19% "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2000 --- loss: 1.242200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[****************************                                            ] 39% "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4000 --- loss: 1.261528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[******************************************                              ] 59% "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6000 --- loss: 1.310667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************************************************               ] 79% "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8000 --- loss: 1.292517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[***********************************************************             ] 82% "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-98321c9b1601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mtrue_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mmasks_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Calculate the loss by comparing the predicted masks vector and true masks vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# And sum the losses together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-118-f3243ef24796>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Specify number of epochs, image scale factor, batch size and learning rate\n",
    "epochs =  100        # e.g. 10, or more until CE converge\n",
    "batch_size = 40    # e.g. 16\n",
    "lr =   0.001          # e.g. 0.01\n",
    "N_train = len(train_img_masks)\n",
    "if not os.path.exists('Model_3'):\n",
    "    os.mkdir('Model_3')\n",
    "model_save_path = 'Model_3/'  # directory to same the model after each epoch. \n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9,weight_decay=0.0005)\n",
    "#suggested parameter settings: momentum=0.9, weight_decay=0.0005\n",
    "\n",
    "# The loss function we use is Cross Entropy\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Start training  #This part takes very long time to run if using CPU\n",
    "for epoch in range(epochs):\n",
    "    print('Starting epoch {}/{}.'.format(epoch + 1, epochs))\n",
    "    net.train()\n",
    "    # Reload images and masks for training and validation and perform random shuffling at the begining of each epoch\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    count = 0\n",
    "    progress.currval = 0\n",
    "    progress.max_value=len(train_loader)-1\n",
    "    progress.start()\n",
    "    for i, b in enumerate(train_loader):\n",
    "        \n",
    "        imgs = b['img'].to(device,dtype=torch.float32)\n",
    "        true_masks = b['label'].to(device,dtype=torch.long)        \n",
    "        masks_pred = net(imgs)\n",
    "        # Calculate the loss by comparing the predicted masks vector and true masks vector\n",
    "        # And sum the losses together \n",
    "        loss = criterion(masks_pred,true_masks.long())\n",
    "        epoch_loss += loss\n",
    "        if count % 20 == 0:  #Print status every 20 batch\n",
    "            print('{0:.4f} --- loss: {1:.6f}'.format(i * batch_size / N_train, loss.item())) \n",
    "        count = count + 1\n",
    "        progress.update(i)\n",
    "        # It’s important to call this before loss.backward(), otherwise you’ll accumulate the gradients from multiple passes.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('Epoch finished ! Loss: {}'.format(epoch_loss / i))\n",
    "    net.eval()\n",
    "    val_cross=0.0\n",
    "    val_tot=1\n",
    "    with torch.no_grad():\n",
    "        progress.currval = 0\n",
    "        progress.max_value=len(val_loader)-1\n",
    "        progress.start()\n",
    "        for i, b in enumerate(val_loader):\n",
    "            vimgs = b['img'].to(device,dtype=torch.float32)\n",
    "            vtrue_masks = b['label'].to(device,dtype=torch.long)\n",
    "            vmasks_pred = net(vimgs)\n",
    "            vloss=criterion(vmasks_pred,vtrue_masks.long())\n",
    "            val_cross += vloss\n",
    "            val_tot=i+1\n",
    "            progress.update(i)\n",
    "    print('Validation Cross-Entropy Coeff: {}'.format(val_cross/i))\n",
    "    \n",
    "    # Save the model after each epoch\n",
    "    if os.path.isdir(model_save_path):\n",
    "        torch.save(net.state_dict(),model_save_path + 'Brain_Seg_Epoch{}.pth'.format(epoch + 1))\n",
    "    else:\n",
    "        os.makedirs(model_save_path, exist_ok=True)\n",
    "        torch.save(net.state_dict(),model_save_path + 'Brain_Seg_Epoch{}.pth'.format(epoch + 1))\n",
    "    print('Checkpoint {} saved !'.format(epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for prediction/testing\n",
    "def predict_img(net,full_img,batch):\n",
    "    # set the mode of your network to evaluation\n",
    "    net.eval()\n",
    "\n",
    "    full_img = np.array(full_img)\n",
    "    test_dataset=torch.from_numpy(full_img).type(torch.FloatTensor)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch, shuffle=False, num_workers=0)\n",
    "    #X_img = X_img.unsqueeze(0)    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # predict the masks\n",
    "        outsy=[]\n",
    "        for i, b in enumerate(test_loader):\n",
    "            imgt = b.to(device,dtype=torch.float32)\n",
    "            #imgt=imgt.to(device,dtype=torch.float32)\n",
    "            output_img = net(imgt)\n",
    "            out_probs = output_img.squeeze(0).squeeze(0)\n",
    "\n",
    "            # change back to numpy, set to uint8 \n",
    "            out_mask_np = out_probs.cpu().numpy().astype(float)\n",
    "            outsy.append(out_mask_np)\n",
    "    return outsy\n",
    "\n",
    "\n",
    "def patchify(imgs,patch_size=(33,33)):\n",
    "    '''\n",
    "        Takes 4 channels of test image and converts into 4-channel patches. Use as input for Segmentation test_loader.\n",
    "        INPUT   (1) list 'imgs': 4-Channels of image\n",
    "                (2) tuple 'patch_size': size of patches to be created\n",
    "        OUTPUT: list of patches and length of this list.\n",
    "        '''\n",
    "    patched=[]\n",
    "    for i in range(4):\n",
    "        patched.append(extract_patches_2d(imgs[i],patch_size))\n",
    "    test_patch=tuple(zip(patched[0],patched[1],patched[2],patched[3]))\n",
    "    print(len(test_patch))\n",
    "    return test_patch,len(test_patch)\n",
    "\n",
    "\n",
    "def depatchify(patches,img_size=(240,240)):\n",
    "    '''\n",
    "        Takes patches of segmented image and reconstructs the original image. Use on output of Segmentation test model.\n",
    "        INPUT   (1) list 'patches': Patches of segmented image obtained from NN output\n",
    "                (2) tuple 'img_size': size of original image  to reconstruct\n",
    "        OUTPUT: Reconstructed, segmented image.\n",
    "        '''\n",
    "    #reconstruct_from_patches_2d(patches,img_size)\n",
    "    return reconstruct_from_patches_2d(patches,img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_segmentation(img_num):\n",
    "    # Load an image from testing dataset\n",
    "    if os.path.exists('Pickles/test_imgs.pickle'):\n",
    "        with open('Pickles/test_imgs.pickle','rb') as f:\n",
    "            test_imgs = pickle.load(f)\n",
    "        f.close()\n",
    "    else:\n",
    "        print('Error! Test Images Pickle not found!')\n",
    "\n",
    "    palt,numt=patchify(test_imgs[img_num],(33,33))\n",
    "    itr_size=100\n",
    "    torch.cuda.empty_cache()\n",
    "    num_itr=int(float(numt)/float(itr_size))\n",
    "    if not (numt%itr_size)==0:\n",
    "        num_itr+=1\n",
    "    patched=predict_img(net,palt[0:itr_size],numt)\n",
    "    for itr in range(num_itr):\n",
    "    #    patched = predict_img(net,palt[0:2000],numt)\n",
    "        if itr<(num_itr-2):\n",
    "            patched.extend(predict_img(net,palt[int((itr+1)*itr_size):int((itr+2)*itr_size)],numt))\n",
    "        elif itr==(num_itr-2):\n",
    "            patched.extend(predict_img(net,palt[int((itr+1)*itr_size):],numt))\n",
    "        else:\n",
    "            continue\n",
    "    patched=np.array(patched)\n",
    "    print(patched.shape)\n",
    "    final_patches_r=[]\n",
    "    final_patches_g=[]\n",
    "    final_patches_b=[]\n",
    "    for i in range(patched.shape[0]):\n",
    "        for j in range(patched[i].shape[0]):\n",
    "            img_seg=np.zeros((3,patched[i].shape[2],patched[i].shape[3]))\n",
    "            #RGB Colour Code-> black(0,0,0):0,else  red(255,0,0):1,necrosis  blue(0,0,255):2,edema  \n",
    "            #green(0,255,0):3,non-enhancing tumor  yellow(255,255,0):4,enhancing tumor\n",
    "            for k in range(patched[i].shape[1]):\n",
    "                img_seg[0] += (patched[i][j][k])*(255.0*(k==1 or k==4))#red\n",
    "                img_seg[1] += (patched[i][j][k])*(255.0*(k==3 or k==4))#green\n",
    "                img_seg[2] += (patched[i][j][k])*(255.0*(k==2))#green\n",
    "            final_patches_r.append(np.array(img_seg[0]))\n",
    "            final_patches_g.append(np.array(img_seg[1]))\n",
    "            final_patches_b.append(np.array(img_seg[2]))\n",
    "    final_patches_r=np.array(final_patches_r)\n",
    "    print(final_patches_r.shape)\n",
    "    final_patches_g=np.array(final_patches_g)\n",
    "    print(final_patches_g.shape)\n",
    "    final_patches_b=np.array(final_patches_b)\n",
    "    print(final_patches_b.shape)\n",
    "    final_patches=[final_patches_r,final_patches_g,final_patches_b]\n",
    "    mask=[]\n",
    "    for i in range(3):\n",
    "          mask.append(depatchify(final_patches[i],(240,240)))\n",
    "    mask=np.array(mask).transpose((1,2,0))\n",
    "    print(mask.shape)\n",
    "\n",
    "    plt.figure(figsize = (10,10))\n",
    "    for i in range(4):\n",
    "        plt.subplot(2,2,i+1)\n",
    "        plt.imshow(test_imgs[img_num][i],cmap='gray')\n",
    "    plt.title(\"4-Channel-Testing Patch {}\".format(img_num))\n",
    "\n",
    "    plt.figure(figsize = (5,5))\n",
    "    plt.imshow(mask,cmap='gray')#vmax=img_seg.max())\n",
    "    plt.title('Tumor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    test_segmentation(i+3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
