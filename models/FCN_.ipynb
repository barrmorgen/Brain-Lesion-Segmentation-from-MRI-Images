{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "from optparse import OptionParser\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "import progressbar\n",
    "from torch.autograd import Function, Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from torchvision import transforms\n",
    "from glob import glob\n",
    "from skimage import io\n",
    "from sklearn.feature_extraction.image import extract_patches_2d,reconstruct_from_patches_2d\n",
    "import pickle\n",
    "from torch.utils.data import Dataset\n",
    "%matplotlib inline\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define base model, VGG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.conv1_1 = nn.Conv2d(4, 64, 3, padding=100)\n",
    "        self.relu1_1 = nn.ReLU(inplace=True)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.relu1_2 = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/2\n",
    "\n",
    "        # conv2\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.relu2_1 = nn.ReLU(inplace=True)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.relu2_2 = nn.ReLU(inplace=True)\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/4\n",
    "\n",
    "        # conv3\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.relu3_1 = nn.ReLU(inplace=True)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.relu3_2 = nn.ReLU(inplace=True)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.relu3_3 = nn.ReLU(inplace=True)\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/8\n",
    "\n",
    "        # conv4\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.relu4_1 = nn.ReLU(inplace=True)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu4_2 = nn.ReLU(inplace=True)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu4_3 = nn.ReLU(inplace=True)\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/16\n",
    "\n",
    "        # conv5\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu5_1 = nn.ReLU(inplace=True)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu5_2 = nn.ReLU(inplace=True)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu5_3 = nn.ReLU(inplace=True)\n",
    "        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/32\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1_1(self.conv1_1(x))\n",
    "        x = self.relu1_2(self.conv1_2(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.relu2_1(self.conv2_1(x))\n",
    "        x = self.relu2_2(self.conv2_2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.relu3_1(self.conv3_1(x))\n",
    "        x = self.relu3_2(self.conv3_2(x))\n",
    "        x = self.relu3_3(self.conv3_3(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.relu4_1(self.conv4_1(x))\n",
    "        x = self.relu4_2(self.conv4_2(x))\n",
    "        x = self.relu4_3(self.conv4_3(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = self.relu5_1(self.conv5_1(x))\n",
    "        x = self.relu5_2(self.conv5_2(x))\n",
    "        x = self.relu5_3(self.conv5_3(x))\n",
    "        x = self.pool5(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define connec. layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(in_channels, out_channles, kernel_size, stride=1, padding=0, bias=True):\n",
    "    layer = nn.Conv2d(in_channels, out_channles, kernel_size, stride, padding, bias=bias)\n",
    "    layer.weight.data.zero_()\n",
    "    if bias:\n",
    "        layer.bias.data.zero_()\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(in_channels, out_channles, bias=True):\n",
    "    layer = nn.Linear(in_channels, out_channles, bias=True)\n",
    "    if bias:\n",
    "        layer.bias.data.zero_()\n",
    "    return layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the FCN model (using VGG model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN16s(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FCN16s, self).__init__()\n",
    "        self.backbone = VGG16()\n",
    "        num_classes = 5\n",
    "\n",
    "        # fc1\n",
    "        self.fc1 = conv_layer(512, 4096, 7)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout2d()\n",
    "\n",
    "        # fc2\n",
    "        self.fc2 = conv_layer(4096, 4096, 1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.drop2 = nn.Dropout2d()\n",
    "\n",
    "        self.score_fr = conv_layer(4096, num_classes, 1)\n",
    "        self.score_pool4 = conv_layer(512, num_classes, 1)\n",
    "\n",
    "        self.upscore2 = bilinear_upsampling(num_classes, num_classes, 4, stride=2, bias=False)\n",
    "        self.upscore16 = bilinear_upsampling(num_classes, num_classes, 32, stride=16, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, _, h, w = x.size()\n",
    "        x = self.backbone.conv1_1(x)\n",
    "        x = self.backbone.relu1_1(x)\n",
    "        x = self.backbone.conv1_2(x)\n",
    "        x = self.backbone.relu1_2(x)\n",
    "        x = self.backbone.pool1(x)\n",
    "\n",
    "        x = self.backbone.conv2_1(x)\n",
    "        x = self.backbone.relu2_1(x)\n",
    "        x = self.backbone.conv2_2(x)\n",
    "        x = self.backbone.relu2_2(x)\n",
    "        x = self.backbone.pool2(x)\n",
    "\n",
    "        x = self.backbone.conv3_1(x)\n",
    "        x = self.backbone.relu3_1(x)\n",
    "        x = self.backbone.conv3_2(x)\n",
    "        x = self.backbone.relu3_2(x)\n",
    "        x = self.backbone.conv3_3(x)\n",
    "        x = self.backbone.relu3_3(x)\n",
    "        x = self.backbone.pool3(x)\n",
    "\n",
    "        x = self.backbone.conv4_1(x)\n",
    "        x = self.backbone.relu4_1(x)\n",
    "        x = self.backbone.conv4_2(x)\n",
    "        x = self.backbone.relu4_2(x)\n",
    "        x = self.backbone.conv4_3(x)\n",
    "        x = self.backbone.relu4_3(x)\n",
    "        x = self.backbone.pool4(x)\n",
    "        pool4 = x  # 1/16\n",
    "\n",
    "        x = self.backbone.conv5_1(x)\n",
    "        x = self.backbone.relu5_1(x)\n",
    "        x = self.backbone.conv5_2(x)\n",
    "        x = self.backbone.relu5_2(x)\n",
    "        x = self.backbone.conv5_3(x)\n",
    "        x = self.backbone.relu5_3(x)\n",
    "        x = self.backbone.pool5(x)\n",
    "        \n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.drop1(x)\n",
    "\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.drop2(x)\n",
    "\n",
    "        x = self.score_fr(x)\n",
    "        x = self.upscore2(x)\n",
    "        upscore2 = x\n",
    "\n",
    "        x = self.score_pool4(pool4)\n",
    "        x = x[:, :, 5:5 + upscore2.size()[2], 5:5 + upscore2.size()[3]]\n",
    "        score_pool4c = x  # 1/16\n",
    "\n",
    "        x = upscore2 + score_pool4c\n",
    "\n",
    "        x = self.upscore16(x)\n",
    "        x = x[:, :, 27:27 + h, 27:27 + w].contiguous()\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DiceCoeff(Function):\n",
    "    \"\"\"Dice coeff for one pair of input image and target image\"\"\"\n",
    "    def forward(self, prediction, target):\n",
    "        self.save_for_backward(prediction, target)\n",
    "        eps = 0.0001 # in case union = 0\n",
    "        \n",
    "        A = prediction.contiguous().view(-1)\n",
    "        B = target.contiguous().view(-1)\n",
    "        self.inter = torch.dot(A, B)\n",
    "        self.union = A.sum()+B.sum()- torch.dot(A, B)+ eps\n",
    "        # Calculate DICE \n",
    "        d = self.inter /  self.union  \n",
    "        return d\n",
    "\n",
    "# Calculate dice coefficients for batches\n",
    "def dice_coeff(prediction, target):\n",
    "    \"\"\"Dice coeff for batches\"\"\"\n",
    "    s = torch.FloatTensor(1).zero_()\n",
    "\n",
    "    for i, (a,b) in enumerate(zip(prediction, target)):\n",
    "        s = DiceCoeff().forward(a,b)  \n",
    "    s = s / (i + 1)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flip(object):\n",
    "    \"\"\"\n",
    "    Flip the image left or right for data augmentation, but prefer original image.\n",
    "    \"\"\"\n",
    "    def __init__(self,ori_probability=0.60):\n",
    "        self.ori_probability = ori_probability\n",
    " \n",
    "    def __call__(self, sample):\n",
    "        if random.uniform(0,1) < self.ori_probability:\n",
    "            return sample\n",
    "        else:\n",
    "            img, label = sample['img'], sample['label']\n",
    "            img_flip = img[:,:,::-1]\n",
    "            label_flip = label[:,::-1]\n",
    "            \n",
    "            return {'img': img_flip, 'label': label_flip}\n",
    "        \n",
    "class ToTensor(object):\n",
    "    \"\"\"\n",
    "    Convert ndarrays in sample to Tensors.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['img'], sample['label']\n",
    "\n",
    "        return {'img': torch.from_numpy(image.copy()).type(torch.FloatTensor),\n",
    "                'label': torch.from_numpy(label.copy()).type(torch.FloatTensor)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_masks, transforms=None): \n",
    "\n",
    "        self.image_masks = image_masks\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):  # return count of sample we have\n",
    "\n",
    "        return len(self.image_masks)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image = np.array(self.image_masks[index][0]) # Channel,H, W\n",
    "        mask = self.image_masks[index][1]\n",
    "        \n",
    "        sample = {'img': image, 'label': mask}\n",
    "        \n",
    "        if transforms:\n",
    "            sample = self.transforms(sample)\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upsampling_weight(in_channels, out_channels, kernel_size):\n",
    "    \"\"\"\n",
    "    Make a 2D bilinear kernel suitable for unsampling\n",
    "    \"\"\"\n",
    "    factor = (kernel_size + 1) // 2\n",
    "    if kernel_size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:kernel_size, :kernel_size]\n",
    "    bilinear_filter = (1 - abs(og[0] - center) / factor) * (1 - abs(og[1] - center) / factor)\n",
    "    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size), dtype=np.float32)\n",
    "    weight[range(in_channels), range(out_channels), :, :] = bilinear_filter\n",
    "    return torch.from_numpy(weight).float()\n",
    "\n",
    "\n",
    "def bilinear_upsampling(in_channels, out_channels, kernel_size, stride, bias=False):\n",
    "    initial_weight = get_upsampling_weight(in_channels, out_channels, kernel_size)\n",
    "    layer = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, bias=bias)\n",
    "    layer.weight.data.copy_(initial_weight)\n",
    "    # weight is frozen because it's just a bilinear upsampling\n",
    "    layer.weight.requires_grad = False\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_masks_save_path = 'Pickles/train_img_masks.pickle'\n",
    "if os.path.exists(train_img_masks_save_path):\n",
    "    with open(train_img_masks_save_path,'rb') as f:\n",
    "        train_img_masks = pickle.load(f)\n",
    "    f.close()\n",
    "else:\n",
    "    pickle_store(train_img_masks_save_path,train_img_masks)\n",
    "\n",
    "val_img_masks_save_path = 'Pickles/val_img_masks.pickle'\n",
    "if os.path.exists(val_img_masks_save_path):\n",
    "    with open(val_img_masks_save_path,'rb') as f:\n",
    "        val_img_masks = pickle.load(f)\n",
    "    f.close()\n",
    "else:\n",
    "    pickle_store(val_img_masks_save_path,val_img_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_img_masks, transforms=transforms.Compose([Flip(),ToTensor()]))\n",
    "val_dataset = CustomDataset(val_img_masks, transforms=transforms.Compose([Flip(),ToTensor()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create net from the FCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCN16s(\n",
      "  (backbone): VGG16(\n",
      "    (conv1_1): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(100, 100))\n",
      "    (relu1_1): ReLU(inplace=True)\n",
      "    (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu1_2): ReLU(inplace=True)\n",
      "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu2_1): ReLU(inplace=True)\n",
      "    (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu2_2): ReLU(inplace=True)\n",
      "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu3_1): ReLU(inplace=True)\n",
      "    (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu3_2): ReLU(inplace=True)\n",
      "    (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu3_3): ReLU(inplace=True)\n",
      "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu4_1): ReLU(inplace=True)\n",
      "    (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu4_2): ReLU(inplace=True)\n",
      "    (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu4_3): ReLU(inplace=True)\n",
      "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu5_1): ReLU(inplace=True)\n",
      "    (conv5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu5_2): ReLU(inplace=True)\n",
      "    (conv5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu5_3): ReLU(inplace=True)\n",
      "    (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (fc1): Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (drop1): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (relu2): ReLU()\n",
      "  (drop2): Dropout(p=0.5, inplace=False)\n",
      "  (score_fr): Conv2d(4096, 5, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (score_pool4): Conv2d(512, 5, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (upscore2): ConvTranspose2d(5, 5, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
      "  (upscore16): ConvTranspose2d(5, 5, kernel_size=(32, 32), stride=(16, 16), bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = FCN16s().to(device,dtype=torch.float32)\n",
    "net.to(device) \n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/10.\n",
      "0.0000 --- loss: 1.609382\n",
      "0.0800 --- loss: 1.609382\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-461b2b1e9053>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtrue_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mmasks_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Calculate the loss by comparing the predicted masks vector and true masks vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# And sum the losses together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-c6b6aee895bf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Specify number of epochs, image scale factor, batch size and learning rate\n",
    "epochs =  10        # e.g. 10, or more until CE converge\n",
    "batch_size = 16    # e.g. 16\n",
    "lr =   0.001          # e.g. 0.01\n",
    "N_train = len(train_img_masks)\n",
    "\n",
    "if not os.path.exists('Model_3'):\n",
    "    os.mkdir('Model_3')\n",
    "model_save_path = 'Model_3/'  # directory to same the model after each epoch. \n",
    "\n",
    "#optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9,weight_decay=1e-4)\n",
    "optimizer=optim.Adam(net.parameters(),lr=lr,weight_decay=1e-4)\n",
    "\n",
    "# The loss function we use is Cross Entropy\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Start training  #This part takes very long time to run if using CPU\n",
    "for epoch in range(epochs):\n",
    "    print('Starting epoch {}/{}.'.format(epoch + 1, epochs))\n",
    "    net.train()\n",
    "    # Reload images and masks for training and validation and perform random shuffling at the begining of each epoch\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    count = 0\n",
    "    for i, b in enumerate(train_loader):\n",
    "        \n",
    "        imgs = b['img'].to(device,dtype=torch.float32)\n",
    "        true_masks = b['label'].to(device,dtype=torch.long)        \n",
    "        masks_pred = net(imgs)\n",
    "        # Calculate the loss by comparing the predicted masks vector and true masks vector\n",
    "        # And sum the losses together \n",
    "        loss = criterion(masks_pred,true_masks.long())\n",
    "        epoch_loss += loss\n",
    "        if count % 20 == 0:  #Print status every 20 batch\n",
    "            print('{0:.4f} --- loss: {1:.6f}'.format(i * batch_size / N_train, loss.item())) \n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
