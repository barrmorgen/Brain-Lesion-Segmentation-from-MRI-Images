{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CE-Net model\n",
    " Implementation of the suggested model suggested by Gu, Z et.al. 2019, for brain lesions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import h5py\n",
    "\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, color, img_as_float\n",
    "\n",
    "\n",
    "from skimage.exposure import adjust_gamma\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from Preprocessing import PatchLibrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Constants\n",
    "nonlinearity = partial(F.relu, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the different parts of the CE-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DACblock(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(DACblock, self).__init__()\n",
    "        self.dilate1 = nn.Conv2d(channel, channel, kernel_size=3, dilation=1, padding=1)\n",
    "        self.dilate2 = nn.Conv2d(channel, channel, kernel_size=3, dilation=3, padding=3)\n",
    "        self.dilate3 = nn.Conv2d(channel, channel, kernel_size=3, dilation=5, padding=5)\n",
    "        self.conv1x1 = nn.Conv2d(channel, channel, kernel_size=1, dilation=1, padding=0)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        dilate1_out = nonlinearity(self.dilate1(x))\n",
    "        dilate2_out = nonlinearity(self.conv1x1(self.dilate2(x)))\n",
    "        dilate3_out = nonlinearity(self.conv1x1(self.dilate2(self.dilate1(x))))\n",
    "        dilate4_out = nonlinearity(self.conv1x1(self.dilate3(self.dilate2(self.dilate1(x)))))\n",
    "        out = x + dilate1_out + dilate2_out + dilate3_out + dilate4_out\n",
    "        return out\n",
    "\n",
    "\n",
    "class DACblock_without_atrous(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(DACblock_without_atrous, self).__init__()\n",
    "        self.dilate1 = nn.Conv2d(channel, channel, kernel_size=3, dilation=1, padding=1)\n",
    "        self.dilate2 = nn.Conv2d(channel, channel, kernel_size=3, dilation=1, padding=1)\n",
    "        self.dilate3 = nn.Conv2d(channel, channel, kernel_size=3, dilation=1, padding=1)\n",
    "        self.conv1x1 = nn.Conv2d(channel, channel, kernel_size=1, dilation=1, padding=0)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        dilate1_out = nonlinearity(self.dilate1(x))\n",
    "        dilate2_out = nonlinearity(self.conv1x1(self.dilate2(x)))\n",
    "        dilate3_out = nonlinearity(self.conv1x1(self.dilate2(self.dilate1(x))))\n",
    "        dilate4_out = nonlinearity(self.conv1x1(self.dilate3(self.dilate2(self.dilate1(x)))))\n",
    "        out = x + dilate1_out + dilate2_out + dilate3_out + dilate4_out\n",
    "\n",
    "        return out\n",
    "\n",
    "class DACblock_with_inception(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(DACblock_with_inception, self).__init__()\n",
    "        self.dilate1 = nn.Conv2d(channel, channel, kernel_size=1, dilation=1, padding=0)\n",
    "\n",
    "        self.dilate3 = nn.Conv2d(channel, channel, kernel_size=3, dilation=1, padding=1)\n",
    "        self.conv1x1 = nn.Conv2d(2 * channel, channel, kernel_size=1, dilation=1, padding=0)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        dilate1_out = nonlinearity(self.dilate1(x))\n",
    "        dilate2_out = nonlinearity(self.dilate3(self.dilate1(x)))\n",
    "        dilate_concat = nonlinearity(self.conv1x1(torch.cat([dilate1_out, dilate2_out], 1)))\n",
    "        dilate3_out = nonlinearity(self.dilate1(dilate_concat))\n",
    "        out = x + dilate3_out\n",
    "        return out\n",
    "\n",
    "\n",
    "class DACblock_with_inception_blocks(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(DACblock_with_inception_blocks, self).__init__()\n",
    "        self.conv1x1 = nn.Conv2d(channel, channel, kernel_size=1, dilation=1, padding=0)\n",
    "        self.conv3x3 = nn.Conv2d(channel, channel, kernel_size=3, dilation=1, padding=1)\n",
    "        self.conv5x5 = nn.Conv2d(channel, channel, kernel_size=5, dilation=1, padding=2)\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        dilate1_out = nonlinearity(self.conv1x1(x))\n",
    "        dilate2_out = nonlinearity(self.conv3x3(self.conv1x1(x)))\n",
    "        dilate3_out = nonlinearity(self.conv5x5(self.conv1x1(x)))\n",
    "        dilate4_out = self.pooling(x)\n",
    "        out = dilate1_out + dilate2_out + dilate3_out + dilate4_out\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class PSPModule(nn.Module):\n",
    "    def __init__(self, features, out_features=1024, sizes=(2, 3, 6, 14)):\n",
    "        super().__init__()\n",
    "        self.stages = []\n",
    "        self.stages = nn.ModuleList([self._make_stage(features, size) for size in sizes])\n",
    "        self.bottleneck = nn.Conv2d(features * (len(sizes) + 1), out_features, kernel_size=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def _make_stage(self, features, size):\n",
    "        prior = nn.AdaptiveAvgPool2d(output_size=(size, size))\n",
    "        conv = nn.Conv2d(features, features, kernel_size=1, bias=False)\n",
    "        return nn.Sequential(prior, conv)\n",
    "\n",
    "    def forward(self, feats):\n",
    "        h, w = feats.size(2), feats.size(3)\n",
    "        priors = [F.upsample(input=stage(feats), size=(h, w), mode='bilinear') for stage in self.stages] + [feats]\n",
    "        bottle = self.bottleneck(torch.cat(priors, 1))\n",
    "        return self.relu(bottle)\n",
    "\n",
    "\n",
    "class SPPblock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(SPPblock, self).__init__()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=[2, 2], stride=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=[3, 3], stride=3)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=[5, 5], stride=5)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=[6, 6], stride=6)\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=1, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.in_channels, h, w = x.size(1), x.size(2), x.size(3)\n",
    "        self.layer1 = F.upsample(self.conv(self.pool1(x)), size=(h, w), mode='bilinear')\n",
    "        self.layer2 = F.upsample(self.conv(self.pool2(x)), size=(h, w), mode='bilinear')\n",
    "        self.layer3 = F.upsample(self.conv(self.pool3(x)), size=(h, w), mode='bilinear')\n",
    "        self.layer4 = F.upsample(self.conv(self.pool4(x)), size=(h, w), mode='bilinear')\n",
    "\n",
    "        out = torch.cat([self.layer1, self.layer2, self.layer3, self.layer4, x], 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, n_filters):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels // 4, 1)\n",
    "        self.norm1 = nn.BatchNorm2d(in_channels // 4)\n",
    "        self.relu1 = nonlinearity\n",
    "\n",
    "        self.deconv2 = nn.ConvTranspose2d(in_channels // 4, in_channels // 4, 3, stride=2, padding=1, output_padding=1)\n",
    "        self.norm2 = nn.BatchNorm2d(in_channels // 4)\n",
    "        self.relu2 = nonlinearity\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels // 4, n_filters, 1)\n",
    "        self.norm3 = nn.BatchNorm2d(n_filters)\n",
    "        self.relu3 = nonlinearity\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.norm3(x)\n",
    "        x = self.relu3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CE_Net_(nn.Module):\n",
    "    def __init__(self, num_classes=1, num_channels=4):\n",
    "        super(CE_Net_, self).__init__()\n",
    "\n",
    "        filters = [64,128,128,128]\n",
    "        resnet = models.resnet34(pretrained=True)\n",
    "        self.firstconv = resnet.conv1\n",
    "        self.firstbn = resnet.bn1\n",
    "        self.firstrelu = resnet.relu\n",
    "        self.firstmaxpool = resnet.maxpool\n",
    "        self.encoder1 = resnet.layer1\n",
    "        self.encoder2 = resnet.layer2\n",
    "        self.encoder3 = resnet.layer3\n",
    "        self.encoder4 = resnet.layer4\n",
    "\n",
    "        self.dblock = DACblock(128)\n",
    "        self.spp = SPPblock(128)\n",
    "\n",
    "        self.decoder4 = DecoderBlock(130, filters[2])\n",
    "        self.decoder3 = DecoderBlock(filters[2], filters[1])\n",
    "        self.decoder2 = DecoderBlock(filters[1], filters[0])\n",
    "        self.decoder1 = DecoderBlock(filters[0], filters[0])\n",
    "\n",
    "        self.finaldeconv1 = nn.ConvTranspose2d(filters[0], 32, 4, 2, 1)\n",
    "        self.finalrelu1 = nonlinearity\n",
    "        self.finalconv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.finalrelu2 = nonlinearity\n",
    "        self.finalconv3 = nn.Conv2d(32, num_classes, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = self.firstconv(x)\n",
    "        x = self.firstbn(x)\n",
    "        x = self.firstrelu(x)\n",
    "        x = self.firstmaxpool(x)\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(e1)\n",
    "        e3 = self.encoder3(e2)\n",
    "        e4 = self.encoder4(e3)\n",
    "\n",
    "        # Center\n",
    "        e4 = self.dblock(e4)\n",
    "        e4 = self.spp(e4)\n",
    "\n",
    "        # Decoder\n",
    "        d4 = self.decoder4(e4) + e3\n",
    "        d3 = self.decoder3(d4) + e2\n",
    "        d2 = self.decoder2(d3) + e1\n",
    "        d1 = self.decoder1(d2)\n",
    "\n",
    "        out = self.finaldeconv1(d1)\n",
    "        out = self.finalrelu1(out)\n",
    "        out = self.finalconv2(out)\n",
    "        out = self.finalrelu2(out)\n",
    "        out = self.finalconv3(out)\n",
    "\n",
    "        return F.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    #X,y = patchGenerator(5,patch_size=(33,33),save=True)\n",
    "    model = CE_Net_()\n",
    "    model.fit_model(X, y)\n",
    "    model.save_model('models/example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CreatePatches.PatchLibrary object at 0x7ff0800476d0>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
