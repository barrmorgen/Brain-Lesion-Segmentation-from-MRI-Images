{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk\n",
    "import progressbar\n",
    "from sklearn.feature_extraction.image import extract_patches_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = progressbar.ProgressBar(widgets=[progressbar.Bar('*', '[', ']'), progressbar.Percentage(), ' '])\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchLibrary(object):\n",
    "    def __init__(self, patch_size, train_data, num_samples):\n",
    "        '''\n",
    "        class for creating patches and subpatches from training data to use as input for segmentation models.\n",
    "        INPUT   (1) tuple 'patch_size': size (in voxels) of patches to extract. Use (33,33) for sequential model\n",
    "                (2) list 'train_data': list of filepaths to all training data saved as pngs. images should have shape (5*240,240)\n",
    "                (3) int 'num_samples': the number of patches to collect from training data.\n",
    "        '''\n",
    "        self.patch_size = patch_size\n",
    "        self.num_samples = num_samples\n",
    "        self.train_data = train_data\n",
    "        self.h = self.patch_size[0]\n",
    "        self.w = self.patch_size[1]\n",
    "\n",
    "    def find_patches(self, class_num, num_patches):\n",
    "        '''\n",
    "        Helper function for sampling slices with evenly distributed classes\n",
    "        INPUT:  (1) list 'training_images': all training images to select from\n",
    "                (2) int 'class_num': class to sample from choice of {0, 1, 2, 3, 4}.\n",
    "                (3) tuple 'patch_size': dimensions of patches to be generated defaults to 65 x 65\n",
    "        OUTPUT: (1) num_samples patches from class 'class_num' randomly selected.\n",
    "        '''\n",
    "        h,w = self.patch_size[0], self.patch_size[1]\n",
    "        patches, labels = [], np.full(num_patches, class_num, 'float')\n",
    "\n",
    "        ct = 0\n",
    "        while ct < num_patches:\n",
    "            im_path = random.choice(self.train_data)\n",
    "            fn = os.path.basename(im_path)\n",
    "            label = io.imread('Labels/' + fn[:-4] + 'L.png')\n",
    "\n",
    "            # resample if class_num not in selected slice\n",
    "            # while len(np.argwhere(label == class_num)) < 10:\n",
    "            #     im_path = random.choice(self.train_data)\n",
    "            #     fn = os.path.basename(im_path)\n",
    "            #     label = io.imread('Labels/' + fn[:-4] + 'L.png')\n",
    "            if len(np.argwhere(label == class_num)) < 10:\n",
    "                continue\n",
    "\n",
    "            # select centerpix (p) and patch (p_ix)\n",
    "            img = io.imread(im_path).reshape(5, 240, 240)[:-1].astype('float')\n",
    "            p = random.choice(np.argwhere(label == class_num))\n",
    "            p_ix = (p[0]-(h/2), p[0]+((h+1)/2), p[1]-(w/2), p[1]+((w+1)/2))\n",
    "            patch = np.array([i[p_ix[0]:p_ix[1], p_ix[2]:p_ix[3]] for i in img])\n",
    "\n",
    "            # resample it patch is empty or too close to edge\n",
    "            # while patch.shape != (4, h, w) or len(np.unique(patch)) == 1:\n",
    "            #     p = random.choice(np.argwhere(label == class_num))\n",
    "            #     p_ix = (p[0]-(h/2), p[0]+((h+1)/2), p[1]-(w/2), p[1]+((w+1)/2))\n",
    "            #     patch = np.array([i[p_ix[0]:p_ix[1], p_ix[2]:p_ix[3]] for i in img])\n",
    "            if patch.shape != (4, h, w) or len(np.argwhere(patch == 0)) > (h * w):\n",
    "                continue\n",
    "\n",
    "            patches.append(patch)\n",
    "            ct += 1\n",
    "        return np.array(patches), labels\n",
    "\n",
    "    def center_n(self, n, patches):\n",
    "        '''\n",
    "        Takes list of patches and returns center nxn for each patch. Use as input for cascaded architectures.\n",
    "        INPUT   (1) int 'n': size of center patch to take (square)\n",
    "                (2) list 'patches': list of patches to take subpatch of\n",
    "        OUTPUT: list of center nxn patches.\n",
    "        '''\n",
    "        sub_patches = []\n",
    "        for mode in patches:\n",
    "            subs = np.array([patch[(self.h/2) - (n/2):(self.h/2) + ((n+1)/2),(self.w/2) - (n/2):(self.w/2) + ((n+1)/2)] for patch in mode])\n",
    "            sub_patches.append(subs)\n",
    "        return np.array(sub_patches)\n",
    "\n",
    "    def slice_to_patches(self, filename):\n",
    "        '''\n",
    "        Converts an image to a list of patches with a stride length of 1. Use as input for image prediction.\n",
    "        INPUT: str 'filename': path to image to be converted to patches\n",
    "        OUTPUT: list of patched version of imput image.\n",
    "        '''\n",
    "        slices = io.imread(filename).astype('float').reshape(5,240,240)[:-1]\n",
    "        plist=[]\n",
    "        for slice in slices:\n",
    "            if np.max(img) != 0:\n",
    "                img /= np.max(img)\n",
    "            p = extract_patches_2d(img, (h,w))\n",
    "            plist.append(p)\n",
    "        return np.array(zip(np.array(plist[0]), np.array(plist[1]), np.array(plist[2]), np.array(plist[3])))\n",
    "\n",
    "    def patches_by_entropy(self, num_patches):\n",
    "        '''\n",
    "        Finds high-entropy patches based on label, allows net to learn borders more effectively.\n",
    "        INPUT: int 'num_patches': defaults to num_samples, enter in quantity it using in conjunction with randomly sampled patches.\n",
    "        OUTPUT: list of patches (num_patches, 4, h, w) selected by highest entropy\n",
    "        '''\n",
    "        patches, labels = [], []\n",
    "        ct = 0\n",
    "        while ct < num_patches:\n",
    "            im_path = random.choice(training_images)\n",
    "            fn = os.path.basename(im_path)\n",
    "            label = io.imread('Labels/' + fn[:-4] + 'L.png')\n",
    "\n",
    "            # pick again if slice is only background\n",
    "            if len(np.unique(label)) == 1:\n",
    "                continue\n",
    "\n",
    "            img = io.imread(im_path).reshape(5, 240, 240)[:-1].astype('float')\n",
    "            l_ent = entropy(label, disk(self.h))\n",
    "            top_ent = np.percentile(l_ent, 90)\n",
    "\n",
    "            # restart if 80th entropy percentile = 0\n",
    "            if top_ent == 0:\n",
    "                continue\n",
    "\n",
    "            highest = np.argwhere(l_ent >= top_ent)\n",
    "            p_s = random.sample(highest, 3)\n",
    "            for p in p_s:\n",
    "                p_ix = (p[0]-(h/2), p[0]+((h+1)/2), p[1]-(w/2), p[1]+((w+1)/2))\n",
    "                patch = np.array([i[p_ix[0]:p_ix[1], p_ix[2]:p_ix[3]] for i in img])\n",
    "                # exclude any patches that are too small\n",
    "                if np.shape(patch) != (4,65,65):\n",
    "                    continue\n",
    "                patches.append(patch)\n",
    "                labels.append(label[p[0],p[1]])\n",
    "            ct += 1\n",
    "            return np.array(patches[:num_samples]), np.array(labels[:num_samples])\n",
    "\n",
    "    def make_training_patches(self, entropy=False, balanced_classes=True, classes=[0,1,2,3,4]):\n",
    "        '''\n",
    "        Creates X and y for training CNN\n",
    "        INPUT   (1) bool 'entropy': if True, half of the patches are chosen based on highest entropy area. defaults to False.\n",
    "                (2) bool 'balanced classes': if True, will produce an equal number of each class from the randomly chosen samples\n",
    "                (3) list 'classes': list of classes to sample from. Only change default oif entropy is False and balanced_classes is True\n",
    "        OUTPUT  (1) X: patches (num_samples, 4_chan, h, w)\n",
    "                (2) y: labels (num_samples,)\n",
    "        '''\n",
    "        if balanced_classes:\n",
    "            per_class = self.num_samples / len(classes)\n",
    "            patches, labels = [], []\n",
    "            progress.currval = 0\n",
    "            for i in range(len(classes)):\n",
    "                p, l = self.find_patches(classes[i], per_class)\n",
    "                # set 0 <= pix intensity <= 1\n",
    "                for img_ix in xrange(len(p)):\n",
    "                    for slice in xrange(len(p[img_ix])):\n",
    "                        if np.max(p[img_ix][slice]) != 0:\n",
    "                            p[img_ix][slice] /= np.max(p[img_ix][slice])\n",
    "                patches.append(p)\n",
    "                labels.append(l)\n",
    "            return np.array(patches).reshape(self.num_samples, 4, self.h, self.w), np.array(labels).reshape(self.num_samples)\n",
    "\n",
    "        else:\n",
    "            print(\"Use balanced classes, random won't work.\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include in segmentation model call:\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_data = glob('train_data/**')\n",
    "    patches = PatchLibrary((33,33), train_data, 50000)\n",
    "    X,y = patches.make_training_patches()\n",
    "\n",
    "    model = SegmentationModel()\n",
    "    model.fit_model(X, y)\n",
    "    model.save_model('models/example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
